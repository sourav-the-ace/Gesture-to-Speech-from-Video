from __future__ import print_function
import numpy as np
import cv2
import os
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K

# Initializing=- 0d4rseyt
batch_size = 64
num_classes = 10
epochs = 100
prediction = 0
pred = 0
data_augmentation = True

# input image dimensions
img_rows, img_cols = 128, 128

# The following 4 list are organized like this x_train = Training Images, y_train = Corresponding Labels of the train images.
# Same goes for x_test,y_test

x_train = []
y_train = []
x_test = []
y_test = []
for i in range(0, 10):
    files = os.listdir('Dataset/train_set/' + str(i) + '/')  # Reads each images of folders one by one
    for file in files:
        filename = 'Dataset/train_set/' + str(i) + '/' + file
        img = cv2.imread(filename, 0)
        img = cv2.resize(img, (128, 128))
        x_train.append(img)
        y_train.append(i)
for i in range(0, 10):
    files = os.listdir('Dataset/test_set/' + str(i) + '/')  # Reads each images of folders one by one

    for file in files:
        filename = 'Dataset/test_set/' + str(i) + '/' + file
        img = cv2.imread(filename, 0)
        img = cv2.resize(img, (128, 128))
        x_test.append(img)
        y_test.append(i)
x_train = np.asarray(x_train)
y_train = np.asarray(y_train)
x_test = np.asarray(x_test)
y_test = np.asarray(y_test)

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

# CNN Model
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
#..........................................
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
#..........................................
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
#..........................................
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.RMSprop(),
              metrics=['accuracy'])
#.............................................

# Augmentation

from keras.preprocessing.image import ImageDataGenerator

if not data_augmentation: #data_augmentation=false
    print('Not using data augmentation.')
    model.fit(x_train, y_train,
              batch_size=batch_size,
              epochs=epochs,
              validation_data=(x_test, y_test),
              shuffle=True)
else: #data_augmentation=true
    print('Using real-time data augmentation.')
    # This will do preprocessing and realtime data augmentation:
    datagen = ImageDataGenerator(rotation_range=30,  # rotate images in the range (degrees,30)
                                 #width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
                                 #height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
                                 shear_range=0.2,  # set range for shear
                                 #zoom_range=0.1,  # set range for zoom
                                 horizontal_flip=True)  # flip images
    # Fit augmented data
    datagen.fit(x_train)

    # Fit the model on the batches generated by datagen.flow().
    model.fit_generator(datagen.flow(x_train, y_train,
                                     batch_size=batch_size),
                        epochs=epochs,
                        validation_data=(x_test, y_test),
                        workers=4)
# Save weight
model.save_weights('With aug 64 batch total dataset.h5')
'''
# Accuracy track
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])'''

# Confusion matrix
from sklearn.metrics import confusion_matrix
ytest = [np.where(r == 1)[0][0] for r in y_test]
Y_pred = model.predict(x_test)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
#print(ytest)
print(confusion_matrix(ytest, y_pred))

''''#Different types of metrics
from sklearn import metrics
#print(metrics.confusion_matrix(ytest, y_pred))
print(metrics.f1_score(ytest, y_pred, average='macro'))
print(metrics.mean_absolute_error(ytest, y_pred))
print(metrics.mean_squared_error(ytest, y_pred))'''